"""
VoxLens: Audio Transcription and Summarization Application
Streamlit UI for speaker diarization, transcription, and summarization
"""
import streamlit as st
import os
import tempfile
from pathlib import Path
import torch

from diarization import SpeakerDiarizer
from transcription import AudioTranscriber
from summarization import ConversationSummarizer
import config


def main():
    """Main Streamlit application"""
    
    # Page configuration
    st.set_page_config(
        page_title="VoxLens - éŸ³å£°æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„",
        page_icon="ğŸ™ï¸",
        layout="wide"
    )
    
    # Title and description
    st.title("ğŸ™ï¸ VoxLens - éŸ³å£°æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„ã‚¢ãƒ—ãƒª")
    st.markdown("""
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆMP3/WAVï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€è©±è€…åˆ†é›¢ã€æ–‡å­—èµ·ã“ã—ã€è¦ç´„ã‚’è¡Œã„ã¾ã™ã€‚
    
    **æ©Ÿèƒ½:**
    - ğŸ—£ï¸ è©±è€…åˆ†é›¢ï¼ˆpyannote.audioï¼‰
    - ğŸ“ æ–‡å­—èµ·ã“ã—ï¼ˆfaster-whisperï¼‰
    - ğŸ“Š AIè¦ç´„ï¼ˆLangChain + Ollamaï¼‰
    """)
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # HuggingFace token for pyannote
        hf_token = st.text_input(
            "HuggingFace Token",
            type="password",
            help="pyannote.audioã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦ã§ã™"
        )
        
        # Device selection
        use_cuda = st.checkbox(
            "CUDAã‚’ä½¿ç”¨",
            value=torch.cuda.is_available(),
            disabled=not torch.cuda.is_available()
        )
        
        # MapReduce option
        use_map_reduce = st.checkbox(
            "é•·ã„æ–‡æ›¸ã«MapReduceã‚’ä½¿ç”¨",
            value=False,
            help="æ–‡å­—æ•°ãŒå¤šã„å ´åˆã«æœ‰åŠ¹"
        )
        
        st.divider()
        st.markdown("""
        **å¿…è¦ãªè¨­å®š:**
        1. HuggingFace Tokenã‚’å…¥åŠ›
        2. OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        3. `llama3.2:8b`ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        
        ```bash
        ollama pull llama3.2:8b
        ```
        """)
    
    # File uploader
    st.header("ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader(
        "MP3ã¾ãŸã¯WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        type=config.SUPPORTED_FORMATS,
        help="å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: MP3, WAV"
    )
    
    if uploaded_file is not None:
        # Display file information
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name} ({uploaded_file.size / 1024:.2f} KB)")
        
        # Process button
        if st.button("ğŸš€ å‡¦ç†é–‹å§‹", type="primary"):
            
            # Validate HuggingFace token
            if not hf_token:
                st.error("âŒ HuggingFace Tokenã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                return
            
            # Save uploaded file to temporary directory
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                audio_path = tmp_file.name
            
            try:
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Step 1: Speaker Diarization
                status_text.text("ğŸ—£ï¸ è©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œä¸­...")
                progress_bar.progress(10)
                
                with st.spinner("è©±è€…ã‚’åˆ†é›¢ã—ã¦ã„ã¾ã™..."):
                    diarizer = SpeakerDiarizer(huggingface_token=hf_token)
                    speaker_segments = diarizer.diarize(audio_path)
                
                st.info(f"æ¤œå‡ºã•ã‚ŒãŸè©±è€…ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(speaker_segments)}")
                progress_bar.progress(35)
                
                # Step 2: Transcription
                status_text.text("ğŸ“ æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­...")
                
                with st.spinner("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ã„ã¾ã™..."):
                    transcriber = AudioTranscriber()
                    full_transcription = transcriber.transcribe_with_speakers(
                        audio_path,
                        speaker_segments
                    )
                
                progress_bar.progress(70)
                
                # Step 3: Summarization
                status_text.text("ğŸ“Š è¦ç´„ã‚’ç”Ÿæˆä¸­...")
                
                with st.spinner("LLMã§è¦ç´„ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                    summarizer = ConversationSummarizer()
                    summary = summarizer.summarize(
                        full_transcription,
                        use_map_reduce=use_map_reduce
                    )
                
                progress_bar.progress(100)
                status_text.text("âœ… å‡¦ç†å®Œäº†ï¼")
                
                # Display results
                st.success("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                # Create two columns for results
                col1, col2 = st.columns(2)
                
                with col1:
                    st.header("ğŸ“„ è©±è€…ãƒ©ãƒ™ãƒ«ä»˜ãå…¨æ–‡")
                    st.text_area(
                        "æ–‡å­—èµ·ã“ã—çµæœ",
                        value=full_transcription,
                        height=400,
                        label_visibility="collapsed"
                    )
                    
                    # Download button for transcription
                    st.download_button(
                        label="ğŸ“¥ å…¨æ–‡ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=full_transcription,
                        file_name="transcription.txt",
                        mime="text/plain"
                    )
                
                with col2:
                    st.header("ğŸ“Š è¦ç´„çµæœ")
                    st.text_area(
                        "è¦ç´„",
                        value=summary,
                        height=400,
                        label_visibility="collapsed"
                    )
                    
                    # Download button for summary
                    st.download_button(
                        label="ğŸ“¥ è¦ç´„ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=summary,
                        file_name="summary.txt",
                        mime="text/plain"
                    )
                
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.exception(e)
            
            finally:
                # Clean up temporary file
                if os.path.exists(audio_path):
                    os.unlink(audio_path)
    
    # Footer
    st.divider()
    st.markdown("""
    <div style='text-align: center; color: gray;'>
        <p>VoxLens - Powered by pyannote.audio, faster-whisper, and LangChain</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
